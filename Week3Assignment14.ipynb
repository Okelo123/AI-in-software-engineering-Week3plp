{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Okelo123/AI-in-software-engineering-Week3plp/blob/main/Week3Assignment14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0QYF-OVRQLA",
        "outputId": "4e13324c-15f4-4144-b36e-437a9ef7590e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Scikit-learn ===\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "=== TensorFlow ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Accuracy: 0.5666666666666667\n",
            "Precision: 0.5818713450292398\n",
            "Recall: 0.5370370370370371\n",
            "\n",
            "=== PyTorch ===\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# üìä Iris Species Classification\n",
        "# Classical ML (Scikit-learn, TensorFlow, PyTorch)\n",
        "# ================================\n",
        "\n",
        "# üîß Install PyTorch if not available (Colab usually has it)\n",
        "# !pip install torch torchvision --quiet\n",
        "\n",
        "# ================================\n",
        "# 1Ô∏è‚É£ Scikit-learn - Decision Tree Classifier\n",
        "# ================================\n",
        "print(\"=== Scikit-learn ===\")\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "\n",
        "# Handle missing values\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ TensorFlow - Neural Network\n",
        "# ================================\n",
        "print(\"\\n=== TensorFlow ===\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_tf_encoded = to_categorical(y_encoded)\n",
        "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X, y_tf_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(10, input_shape=(4,), activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_tf, y_train_tf, epochs=50, verbose=0)\n",
        "\n",
        "# Predict\n",
        "y_pred_probs = model.predict(X_test_tf)\n",
        "y_pred_tf = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_tf = np.argmax(y_test_tf, axis=1)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_true_tf, y_pred_tf))\n",
        "print(\"Precision:\", precision_score(y_true_tf, y_pred_tf, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_true_tf, y_pred_tf, average='macro'))\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ PyTorch - Neural Network\n",
        "# ================================\n",
        "print(\"\\n=== PyTorch ===\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "X_train_pt, X_test_pt, y_train_pt, y_test_pt = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train_pt = torch.FloatTensor(X_train_pt.values)\n",
        "X_test_pt = torch.FloatTensor(X_test_pt.values)\n",
        "y_train_pt = torch.LongTensor(y_train_pt)\n",
        "y_test_pt = torch.LongTensor(y_test_pt)\n",
        "\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 3)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model_pt = IrisNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_pt.parameters(), lr=0.01)\n",
        "\n",
        "# Training\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_pt(X_train_pt)\n",
        "    loss = criterion(outputs, y_train_pt)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Prediction\n",
        "with torch.no_grad():\n",
        "    y_pred_pt = model_pt(X_test_pt)\n",
        "    y_pred_classes_pt = torch.argmax(y_pred_pt, dim=1)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test_pt, y_pred_classes_pt))\n",
        "print(\"Precision:\", precision_score(y_test_pt, y_pred_classes_pt, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test_pt, y_pred_classes_pt, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Comparative Analysis: Scikit-learn vs TensorFlow\n",
        "\n",
        "| Feature              | Scikit-learn                         | TensorFlow                             |\n",
        "|----------------------|--------------------------------------|----------------------------------------|\n",
        "| **Type**             | Machine Learning library (classical ML) | Deep Learning framework                |\n",
        "| **Primary Use**      | Quick models: regression, classification | Neural networks, CNNs, NLP, large-scale models |\n",
        "| **Learning Curve**   | Very easy to learn                   | Steeper, more flexible                 |\n",
        "| **Deployment**       | Joblib, ONNX                         | TF Lite, TF Serving, TensorFlow.js     |\n",
        "| **Community Support**| Huge for ML beginners                | Very active, cutting-edge AI research  |\n",
        "| **Best For**         | Tabular data, quick experimentation  | Deep learning tasks, production-ready systems |\n",
        "\n",
        "### ‚úÖ Summary\n",
        "- Scikit-learn is fast and perfect for classical ML tasks (e.g., Iris classification).\n",
        "- TensorFlow is ideal when working with images, sequences, or large datasets (e.g., MNIST, CNNs)."
      ],
      "metadata": {
        "id": "W2_NUXk5_BGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Deep Learning with TensorFlow on MNIST\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. Preprocess the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "# 3. Build CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "# 6. Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"\\n‚úÖ Test accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# 7. Visualize predictions on 5 sample images\n",
        "def visualize_predictions(model, x_test, y_test):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(5):\n",
        "        idx = np.random.randint(0, len(x_test))\n",
        "        img = x_test[idx]\n",
        "        true_label = y_test[idx]\n",
        "        pred = np.argmax(model.predict(img.reshape(1, 28, 28, 1)), axis=1)[0]\n",
        "\n",
        "        plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(img.reshape(28, 28), cmap='gray')\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "uiymAyjOlW8i",
        "outputId": "bda43ec0-437c-42b0-af27-e301136ed01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 26ms/step - accuracy: 0.8991 - loss: 0.3124 - val_accuracy: 0.9855 - val_loss: 0.0513\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9854 - loss: 0.0463 - val_accuracy: 0.9883 - val_loss: 0.0414\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0284 - val_accuracy: 0.9877 - val_loss: 0.0443\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 27ms/step - accuracy: 0.9942 - loss: 0.0185 - val_accuracy: 0.9888 - val_loss: 0.0389\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9953 - loss: 0.0155 - val_accuracy: 0.9910 - val_loss: 0.0345\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0363\n",
            "\n",
            "‚úÖ Test accuracy: 99.06%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ†Ô∏è Buggy Code Debugger ‚Äì TensorFlow Classification\n",
        "\n",
        "This section demonstrates a simple TensorFlow neural network that contains common **mistakes beginners make**.\n",
        "\n",
        "## ‚ùå Buggy Code Issues:\n",
        "| Problem | Explanation |\n",
        "|--------|-------------|\n",
        "| ‚ùå No `softmax` activation on final layer | This prevents outputs from being proper class probabilities. |\n",
        "| ‚ùå Wrong loss function (`mse`) | MSE is used for regression, not classification. |\n",
        "| ‚ùå Data not defined | Code tries to train without loading or preparing any dataset (`x_train`, `y_train` are undefined). |\n",
        "\n",
        "We'll fix this by:\n",
        "- Loading the MNIST dataset\n",
        "- Preprocessing it correctly\n",
        "- Using a proper model architecture for classification"
      ],
      "metadata": {
        "id": "-RCt4540CQFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ‚ùå Buggy Code Example (Do not run)\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, input_shape=(784,), activation='relu'),\n",
        "    tf.keras.layers.Dense(10)  # ‚ùå No activation like softmax\n",
        "])\n",
        "\n",
        "# ‚ùå Wrong loss for classification\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "# ‚ùå Data not defined\n",
        "model.fit(x_train, y_train, epochs=5)  # x_train and y_train are undefined\n",
        "x_train not defined"
      ],
      "metadata": {
        "id": "lNvVuoOr_us9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Fixed Version: TensorFlow Neural Network for Classification\n",
        "\n",
        "This corrected version:\n",
        "- Loads the MNIST dataset\n",
        "- Flattens and normalizes image input data\n",
        "- One-hot encodes the target labels for multi-class classification\n",
        "- Adds `softmax` activation in the output layer\n",
        "- Uses `categorical_crossentropy` as the correct loss function"
      ],
      "metadata": {
        "id": "czANO1BXC5VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ‚úÖ Import required libraries\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "# ‚úÖ Step 1: Load the MNIST handwritten digits dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# ‚úÖ Step 2: Flatten the 28x28 images into 784-length vectors and normalize pixel values\n",
        "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
        "\n",
        "# ‚úÖ Step 3: Convert integer labels (0‚Äì9) into one-hot encoded vectors\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# ‚úÖ Step 4: Build the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_shape=(784,), activation='relu'),  # Hidden layer with ReLU\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # Output layer with softmax for classification\n",
        "])\n",
        "\n",
        "# ‚úÖ Step 5: Compile the model with the correct loss function and optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ‚úÖ Step 6: Train the model\n",
        "model.fit(x_train, y_train_cat, epochs=5, validation_split=0.1)"
      ],
      "metadata": {
        "id": "gOskDkrC_7RV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd42db66-6ea9-4252-df11-4f3dd6708273"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.8676 - loss: 0.4579 - val_accuracy: 0.9647 - val_loss: 0.1215\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.1249 - val_accuracy: 0.9707 - val_loss: 0.1012\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0855 - val_accuracy: 0.9758 - val_loss: 0.0862\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0583 - val_accuracy: 0.9745 - val_loss: 0.0857\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0452 - val_accuracy: 0.9765 - val_loss: 0.0836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c839d83e610>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öñÔ∏è Ethical Analysis of AI Systems\n",
        "\n",
        "### 1. üîç Bias and Fairness\n",
        "AI systems may inherit biases from the data (e.g., gender, race). Example: A sentiment analysis model trained on toxic forums may unfairly score neutral posts from minorities as negative.\n",
        "\n",
        "**Solution**: Use diverse training datasets, perform fairness audits, and retrain with debiased data.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. üîê Privacy & Data Use\n",
        "Training models on personal or sensitive data (health, location, voice) without consent violates ethical norms.\n",
        "\n",
        "**Solution**: Apply anonymization, secure storage, and user consent policies. Use federated learning when possible.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. üß† Explainability\n",
        "Deep learning models often operate as \"black boxes\" which makes trust and debugging difficult.\n",
        "\n",
        "**Solution**: Use explainability tools like SHAP, LIME, or XAI dashboards to make decisions transparent.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. üå± Environmental Impact\n",
        "Large models (e.g., GPT, BERT) consume massive energy. Training them without optimization harms sustainability.\n",
        "\n",
        "**Solution**: Use transfer learning, pruning, quantization, and efficient hardware (TPUs, edge ML).\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Responsible AI Practices\n",
        "- Involve interdisciplinary teams\n",
        "- Set AI ethics guidelines (e.g., Google's Responsible AI)\n",
        "- Include human-in-the-loop decision-making"
      ],
      "metadata": {
        "id": "D9Qkkmo-AEdU"
      }
    }
  ]
}